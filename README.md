# ğŸ§ Music Genre & Tag Classification using Deep Learning

This project explores **music understanding through deep learning** using **spectrogram-based EfficientNet models**.  
It includes **four experiments** across two datasets:

- **FMA-Small** â†’ Single-label genre classification  
- **MagnaTagATune (MTAT)** â†’ Single-label main-genre + multi-label tagging  

The work covers dataset preparation, spectrogram generation, 6-second chunk processing, EfficientNet training, augmentation, and evaluation.

---

## ğŸ“Œ Project Overview

Music contains rich information:
- Genre  
- Instruments  
- Mood  
- Tempo  
- Vocals  

This project processes audio into **3-channel spectrogram images**:

| Channel | Description |
|--------|-------------|
| **Mel-spectrogram (256 bins)** | Timbre + frequency content |
| **MFCC** | Texture, articulation, brightness |
| **Chroma** | Harmony and pitch class |

Models are trained using:
- **EfficientNet-B2/B4**
- **Binary Cross Entropy (for multi-label)**
- **Cross Entropy (for single-label)**
- **FastAI**
- **SpecAugment** (time/frequency masking)
- **FP16 mixed precision**
- **Dynamic thresholding for multi-label**

---

# ğŸ§ª Experiments

Below is a summary of the 4 experiments conducted.

---

## âœ… **Experiment 1 â€” FMA-Small (Baseline ResNet50)**

**Task:** Single-label classification (8 genres)  
**Dataset:** 8,000 tracks â†’ ~75k spectrogram images  
**Model:** ResNet50  
**Goal:** Build baseline + verify preprocessing pipeline  

**Result:**  
**~59% accuracy**

---

## âœ… **Experiment 2 â€” FMA-Small (EfficientNet-B2/B4)**

**Task:** Same as Experiment 1, with enhanced audio features  
**Features Added:**
- 6-second chunks  
- 3-channel spectrograms (Mel + MFCC + Chroma)  
- SpecAugment  
- EfficientNet-B2 and B4  

**Result:**  
**~53% accuracy** (limited by dataset noise & size)

---

## âœ… **Experiment 3 â€” MTAT Single-Label ("Main Genre")**

Converted multi-label tags â†’ a single dominant genre.

**Classes:**  
`classical, electronic, rock, ambient, folk, jazz, pop, hiphop, metal`

**Dataset Size After Cleaning:** ~45k spectrograms  
**Model:** EfficientNet-B4  

**Result:**  
**78% test accuracy**

---

## ğŸ¯ **Experiment 4 â€” MTAT Multi-Label Tagging (Final Model)**

**Task:** Predict all relevant tags for each clip:  
- Instruments  
- Genre  
- Mood  
- Tempo  
- Vocals  

**Model:** EfficientNet-B2 (BCEWithLogitsLoss)  
**Evaluation:** Micro F1-score + threshold tuning  

**Result:**  
**F1 â‰ˆ 0.43**  
Comparable to published MTAT research benchmarks.

---

# ğŸ“ Project Structure
music-classification/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ fma_small_tracks_genre_top.csv
â”‚ â”œâ”€â”€ mtat_singlelabel_genres.csv
â”‚ â””â”€â”€ mtat_spectrogram_chunks.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 03_MTAG_MainGenre.ipynb
â”‚ â”œâ”€â”€ dataset_01_FMA_ResNet50.ipynb
â”‚ â”œâ”€â”€ dataset_02_FMA_EfficientNet.ipynb
â”‚ â”œâ”€â”€ dataset_04_MTAG_MultiLabel.ipynb
â”‚ â”œâ”€â”€ Training_01_FMA_ResNet50.ipynb
â”‚ â”œâ”€â”€ Training_02_FMA_EfficientNet.ipynb
â”‚ â””â”€â”€ Training_04_MTAG_MultiLabel.ipynb

â”‚
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ effnet_b2_fma_small_v2_export.pkl
â”‚ â”œâ”€â”€ effnet_b2_fma_small_v2.pth
â”‚ â”œâ”€â”€ effnet_b2_MagnaTagATune_v2.pkl
â”‚ â”œâ”€â”€ effnet_b2_MagnaTagATune_v2.pth
â”‚ â”œâ”€â”€ effnet_b4_MagnaTagATune_v2_single_label.pkl
â”‚ â”œâ”€â”€ effnet_b4_MagnaTagATune_v2_single_label.pth
â”‚ â”œâ”€â”€ resnet50_fma_small_export.pkl
â”‚ â””â”€â”€ resnet50_fma_small_stage1.pth
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

# ğŸ™Œ Acknowledgements

Datasets:  
- **FMA Dataset** (Defferrard et al.)  
- **MagnaTagATune (MTAT)**  
Tools:  
- FastAI  
- Librosa  
- PyTorch  
- OpenXLab (dataset hosting)